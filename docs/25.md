# 安全

默认情况下，所有门都是打开的。限制对Web应用程序的访问的一种简单方法是在网络级别执行此操作，比如使用SSH隧道。

但也可以通过使用其中一个已提供的认证后端或创建自己的认证后端来打开身份验证。

请务必查看[Experimental Rest API](zh/27.md)以保护API。

## Web身份验证

### 密码

最简单的身份验证机制之一是要求用户在登录前输入密码。密码身份验证需要在requirements文件中使用`password`子扩展包。它在存储密码之前使用了bcrypt扩展包来对密码进行哈希。

```
[webserver]
authenticate = True
auth_backend = airflow.contrib.auth.backends.password_auth
```

启用密码身份验证后，需要先创建初始用户凭据，然后才能登录其他人。未在此身份验证后端的迁移中创建初始用户，以防止默认Airflow安装受到攻击。必须通过安装Airflow的同一台机器上的Python REPL来创建新用户。

```py
# navigate to the airflow installation directory
$ cd ~/airflow
$ python
Python 2.7.9 (default, Feb 10 2015, 03:28:08)
Type "help", "copyright", "credits" or "license" for more information.
>>> import airflow
>>> from airflow import models, settings
>>> from airflow.contrib.auth.backends.password_auth import PasswordUser
>>> user = PasswordUser(models.User())
>>> user.username = 'new_user_name'
>>> user.email = 'new_user_email@example.com'
>>> user.password = 'set_the_password'
>>> session = settings.Session()
>>> session.add(user)
>>> session.commit()
>>> session.close()
>>> exit()
```

### LDAP

要打开LDAP身份验证，请按如下方式配置`airflow.cfg`。请注意，该示例使用与ldap服务器的加密连接，因为您可能不希望密码在网络级别上可读。 但是，如果您真的想要，可以在不加密的情况下进行配置。

此外，如果您使用的是Active Directory，并且没有明确指定用户所在的OU，则需要将`search_scope`更改为“SUBTREE”。

有效的search_scope选项可以在[ldap3文档中](https://ldap3.readthedocs.org/searches.html%3Fhighlight%3Dsearch_scope)找到

```
[webserver]
authenticate = True
auth_backend = airflow.contrib.auth.backends.ldap_auth

[ldap]
# set a connection without encryption: uri = ldap://<your.ldap.server>:<port>
uri = ldaps://<your.ldap.server>:<port>
user_filter = objectClass=*
# in case of Active Directory you would use: user_name_attr = sAMAccountName
user_name_attr = uid
# group_member_attr should be set accordingly with *_filter
# eg :
#     group_member_attr = groupMembership
#     superuser_filter = groupMembership=CN=airflow-super-users...
group_member_attr = memberOf
superuser_filter = memberOf=CN=airflow-super-users,OU=Groups,OU=RWC,OU=US,OU=NORAM,DC=example,DC=com
data_profiler_filter = memberOf=CN=airflow-data-profilers,OU=Groups,OU=RWC,OU=US,OU=NORAM,DC=example,DC=com
bind_user = cn=Manager,dc=example,dc=com
bind_password = insecure
basedn = dc=example,dc=com
cacert = /etc/ca/ldap_ca.crt
# Set search_scope to one of them: BASE, LEVEL, SUBTREE
# Set search_scope to SUBTREE if using Active Directory, and not specifying an Organizational Unit
search_scope = LEVEL
```

superuser_filter和data_profiler_filter是可选的。如果已定义，则这些配置允许您指定用户必须属于的LDAP组，以便拥有超级用户（admin）和数据分析权限。如果未定义，则所有用户都将成为超级用户和拥有数据分析的权限。

### 创建自定义

Airflow使用了`flask_login`扩展包并在`airflow.default_login`模块中公开了一组钩子。您可以更改内容并使其成为`PYTHONPATH`一部分，并将其配置为`airflow.cfg`的认证后端。

```
[webserver]
authenticate = True
auth_backend = mypackage.auth
```

## 多租户

通过在配置中设置`webserver:filter_by_owner`，可以在启用身份验证时按所有者名称筛选`webserver:filter_by_owner`。有了这个，用户将只看到他所有者的dags，除非他是超级用户。

```
[webserver]
filter_by_owner = True
```

## Kerberos

Airflow天然支持Kerberos。这意味着Airflow可以为自己更新kerberos票证并将其存储在票证缓存中。钩子和dags可以使用票证来验证kerberized服务。

### 限制

请注意，此时并未调整所有钩子以使用此功能。此外，它没有将kerberos集成到Web界面中，您现在必须依赖网络级安全性来确保您的服务保持安全。

Celery集成尚未经过试用和测试。 但是，如果您为每个主机生成一个key tab，并在每个Worker旁边启动一个ticket renewer，那么它很可能会起作用。

### 启用kerberos

#### Airflow

要启用kerberos，您需要生成（服务）key tab。

```py
# in the kadmin.local or kadmin shell, create the airflow principal
kadmin:  addprinc -randkey airflow/fully.qualified.domain.name@YOUR-REALM.COM

# Create the airflow keytab file that will contain the airflow principal
kadmin:  xst -norandkey -k airflow.keytab airflow/fully.qualified.domain.name
```

现在将此文件存储在airflow用户可以读取的位置（chmod 600）。然后将以下内容添加到`airflow.cfg`

```
[core]
security = kerberos

[kerberos]
keytab = /etc/airflow/airflow.keytab
reinit_frequency = 3600
principal = airflow

```

启动ticket renewer

```sh
# run ticket renewer
airflow kerberos
```

#### Hadoop

如果要使用模拟，则需要在hadoop配置的`core-site.xml`中启用。

```
<property>
  <name>hadoop.proxyuser.airflow.groups</name>
  <value>*</value>
</property>

<property>
  <name>hadoop.proxyuser.airflow.users</name>
  <value>*</value>
</property>

<property>
  <name>hadoop.proxyuser.airflow.hosts</name>
  <value>*</value>
</property>

```

当然，如果您需要加强安全性，请用更合适的东西替换星号。

### 使用kerberos身份验证

已更新Hive钩子以利用kerberos身份验证。要允许DAG使用它，只需更新连接详细信息，例如：

```
{"use_beeline": true, "principal": "hive/_HOST@EXAMPLE.COM"}
```

请根据您的设置进行调整。_HOST部分将替换为服务器的完全限定域名。

您可以指定是否要将dag所有者用作连接的用户或连接的登录部分中指定的用户。对于登录用户，请将以下内容指定为额外：
```
{"use_beeline": true, "principal": "hive/_HOST@EXAMPLE.COM", "proxy_user": "login"}
```

对于DAG所有者使用：
```
{"use_beeline": true, "principal": "hive/_HOST@EXAMPLE.COM", "proxy_user": "owner"}
```

在DAG中，初始化HiveOperator时，请指定：
```
run_as_owner = True
```

为了使用kerberos认证，请务必在安装Airflow时添加kerberos子扩展包：
```
pip install airflow[kerberos]
```

## OAuth认证

### GitHub Enterprise（GHE）认证

GitHub Enterprise认证后端可用于对使用OAuth2安装GitHub Enterprise的用户进行身份认证。您可以选择指定团队白名单（由slug cased团队名称组成）以限制仅允许这些团队的成员登录。

```
[webserver]
authenticate = True
auth_backend = airflow.contrib.auth.backends.github_enterprise_auth

[github_enterprise]
host = github.example.com
client_id = oauth_key_from_github_enterprise
client_secret = oauth_secret_from_github_enterprise
oauth_callback_route = /example/ghe_oauth/callback
allowed_teams = 1, 345, 23
```

注意

如果您未指定团队白名单，那么在GHE安装中拥有有效帐户的任何人都可以登录Airflow。

#### 设置GHE身份验证

必须先在GHE中设置应用程序，然后才能使用GHE身份验证后端。 要设置应用程序：

1. 导航到您的GHE配置文件
2. 从左侧导航栏中选择“应用程序”
3. 选择“开发者应用程序”选项卡
4. 点击“注册新申请”
5. 填写所需信息（“授权回调URL”必须完全合格，例如[http://airflow.example.com/example/ghe_oauth/callback](http://airflow.example.com/example/ghe_oauth/callback) ）
6. 点击“注册申请”
7. 根据上面的示例，将“客户端ID”，“客户端密钥”和回调路由复制到airflow.cfg

#### 在github.com上使用GHE身份验证

可以在github.com上使用GHE身份验证：

1. [创建一个Oauth应用程序](https://developer.github.com/apps/building-oauth-apps/creating-an-oauth-app/)
2. 根据上面的示例，将“客户端ID”，“客户端密钥”复制到airflow.cfg
3. 在airflow.cfg设置`host = github.com`和`oauth_callback_route = /oauth/callback`

### Google身份验证

Google身份验证后端可用于使用OAuth2对Google用户进行身份验证。您必须指定电子邮件域以限制登录（以逗号分隔），仅限于这些域的成员。

```
[webserver]
authenticate = True
auth_backend = airflow.contrib.auth.backends.google_auth

[google]
client_id = google_client_id
client_secret = google_client_secret
oauth_callback_route = /oauth2callback
domain = "example1.com,example2.com"
```

#### 设置Google身份验证

必须先在Google API控制台中设置应用程序，然后才能使用Google身份验证后端。 要设置应用程序：

1. 导航到[https://console.developers.google.com/apis/](https://console.developers.google.com/apis/)
2. 从左侧导航栏中选择“凭据”
3. 点击“创建凭据”，然后选择“OAuth客户端ID”
4. 选择“Web应用程序”
5. 填写所需信息（'授权重定向URI'必须完全合格，例如[http://airflow.example.com/oauth2callback](http://airflow.example.com/oauth2callback) ）
6. 点击“创建”
7. 根据上面的示例，将“客户端ID”，“客户端密钥”和重定向URI复制到airflow.cfg

## SSL

可以通过提供证书和密钥来启用SSL。启用后，请务必在浏览器中使用“[https//](https:)”。

```
[webserver]
web_server_ssl_cert = <path to cert>
web_server_ssl_key = <path to key>
```

启用S​​SL不会自动更改Web服务器端口。如果要使用标准端口443，则还需要配置它。请注意，侦听端口443需要超级用户权限（或Linux上的cap_net_bind_service）。

```py
# Optionally, set the server to listen on the standard SSL port.
web_server_port = 443
base_url = http://<hostname or IP>:443
```

使用SSL启用CeleryExecutor。 确保正确生成客户端和服务器证书和密钥。

```
[celery]
CELERY_SSL_ACTIVE = True
CELERY_SSL_KEY = <path to key>
CELERY_SSL_CERT = <path to cert>
CELERY_SSL_CACERT = <path to cacert>
```

## 模拟

Airflow能够在运行任务实例时模拟unix用户，该任务实例基于任务的`run_as_user`参数，该参数采用用户的名称。

**注意：**
要模拟工作，必须使用`sudo`运行Airflow，因为使用`sudo -u`运行子任务并更改文件的权限。此外，unix用户需要存在于worker中。假设airflow是`airflow`用户运行，一个简单的sudoers文件可能看起来像这样。请注意，这意味着必须以与root用户相同的方式信任和处理airflow用户。

```
airflow ALL=(ALL) NOPASSWD: ALL
```

带模拟的子任务仍将记录到同一文件夹，但他们登录的文件将更改权限，只有unix用户才能写入。

### 默认模拟

要防止不使用模拟的任务以`sudo`权限运行，如果未设置`run_as_user`，可以在`core:default_impersonation`配置中来设置默认的模拟用户。

```
[core]
default_impersonation = airflow
```

## Flower认证

Celery Flower的基础认证是支持的。

可以在Flower进程启动命令中指定可选参数，或者在`airflow.cfg`指定配置项。对于这两种情况，请提供用逗号分隔的user:password对。

```sh
airflow flower --basic_auth=user1:password1,user2:password2
```

```
[celery]
flower_basic_auth = user1:password1,user2:password2
```
